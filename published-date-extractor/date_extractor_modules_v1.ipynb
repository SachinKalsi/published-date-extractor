{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import NavigableString\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HtmlEncoder():\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.soup = self.get_soup()\n",
    "        self.__df = None\n",
    "            \n",
    "    def get_soup(self):\n",
    "        res = self.__read_html()\n",
    "        soup = BeautifulSoup(res.text)\n",
    "        soup = self.__pre_cleaning(soup)\n",
    "        return soup\n",
    "    \n",
    "    def __pre_cleaning(self, soup):\n",
    "        for script in soup([\"script\", \"footer\", \"nav\", \"head\"]):  # remove all javascript code\n",
    "            script.decompose()\n",
    "        return soup\n",
    "        \n",
    "    def __read_html(self):\n",
    "        return requests.get(self.url)\n",
    "        \n",
    "    def __clean_text(self, text):\n",
    "        if not text:\n",
    "            return ''\n",
    "        text = text.lower()\n",
    "        text = text.encode('ascii', errors='ignore').decode(\"utf-8\")\n",
    "        text = text.replace('\\n', '')\n",
    "        text = text.replace('\\r', '')\n",
    "        text = text.replace('\\t', '')\n",
    "        text = text.replace(' ','')\n",
    "        return text\n",
    "    \n",
    "    def __get_tag_depth(self, tag):\n",
    "        count = 0\n",
    "        while tag and tag.name != 'body':\n",
    "            count += len([t for t in tag.previous_siblings if (type(t) != NavigableString and t.name!=None)])\n",
    "            tag = tag.parent\n",
    "        return count\n",
    "\n",
    "    def __get_siblings(self, tag):\n",
    "        prev_siblings = [t.name for t in tag.previous_siblings if (type(t) != NavigableString and t.name!=None)]\n",
    "        next_siblings = [t.name for t in tag.next_siblings if  (type(t) != NavigableString and t.name!=None)]\n",
    "        return prev_siblings, next_siblings\n",
    "\n",
    "    def __get_total_ancestors(self, tag):\n",
    "        level = 0\n",
    "        while tag and tag.name != 'html':\n",
    "            tag = tag.parent\n",
    "            level += 1\n",
    "        return level\n",
    "\n",
    "    def __get_core_tag_attr(self, tag):\n",
    "        tag_name = tag.name\n",
    "        parent_tag_name = None\n",
    "        if tag.parent:\n",
    "            parent_tag_name = tag.parent.name\n",
    "        ancestors_count = self.__get_total_ancestors(tag)\n",
    "        tag_depth = self.__get_tag_depth(tag)\n",
    "        return {'tag_name': tag_name, 'parent_tag_name': parent_tag_name, 'ancestors_count': ancestors_count, 'tag_depth':tag_depth}\n",
    "\n",
    "    def __get_childrens_attr(self, tag):\n",
    "        childrens = tag.find_all()\n",
    "        children_count = len(childrens)\n",
    "        children_types = [t.name for t in childrens]\n",
    "        return {'children_count': children_count}#, 'children_types': children_types}\n",
    "\n",
    "    def __get_sibling_attr(self, tag):\n",
    "        left_siblings, right_siblings = self.__get_siblings(tag)\n",
    "        siblings_length = len(left_siblings) + len(right_siblings)\n",
    "        tag_position_among_siblings = len(left_siblings) + 1\n",
    "        return {'left_siblings': left_siblings, 'right_siblings': right_siblings, 'tag_position_among_siblings': tag_position_among_siblings}\n",
    "\n",
    "    def __get_tag_text_attr(self, tag):\n",
    "        text = tag.text\n",
    "        text_length = len(text.strip())\n",
    "        clean_text_length = len(self.__clean_text(text))\n",
    "        total_numerical_groups = len(re.findall(r'\\d+', text)) # ['21', '2019']\n",
    "        total_numbericals = len(re.findall(r'\\d',text))\n",
    "        return {'text_length': text_length, 'total_numerical_groups': total_numerical_groups,\n",
    "                'total_numbericals': total_numbericals, 'text':text,\n",
    "               'clean_text_length': clean_text_length}\n",
    "\n",
    "    def __get_class_related_attr(self, tag):\n",
    "        \"\"\"\n",
    "        returns length of classes & number of classes\n",
    "        \"\"\"\n",
    "        total_classes = 0\n",
    "        class_text = None\n",
    "        classes = tag.get('class')\n",
    "        if classes:\n",
    "            total_classes = len(classes)\n",
    "            class_text = ' '.join(classes)\n",
    "        return { 'total_classes': total_classes, 'class_text': class_text }\n",
    "    \n",
    "    def get_featurization_functions(self):\n",
    "        function_list = [self.__get_core_tag_attr, \n",
    "                         self.__get_childrens_attr, \n",
    "                         self.__get_sibling_attr, \n",
    "                         self.__get_tag_text_attr,\n",
    "                         self.__get_class_related_attr]\n",
    "        return function_list        \n",
    "    \n",
    "    def featurize_tag(self, tag):\n",
    "        if type(tag) == NavigableString or tag.name in ['html', 'body']:\n",
    "            return None\n",
    "        all_functions = self.get_featurization_functions()\n",
    "        data = {}\n",
    "        for func in all_functions:\n",
    "            data_dict =  func(tag)\n",
    "            for key, value in data_dict.items():\n",
    "                data[key] = value\n",
    "        return data\n",
    "    \n",
    "    def __set_html_df(self, df):\n",
    "        self.__df = df\n",
    "    \n",
    "    def get_html_df(self):\n",
    "        return self.__df\n",
    "    \n",
    "    def transform(self):\n",
    "        all_data = []\n",
    "        all_tags = self.soup.find_all()\n",
    "        for tag in all_tags:\n",
    "            data = self.featurize_tag(tag)\n",
    "            if data:\n",
    "                all_data.append(data)\n",
    "        self.__set_html_df(pd.DataFrame(all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump, load\n",
    "\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.20.2 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.20.2 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.20.2 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "tag_name_encoder = load('tag_name_encoder.joblib') \n",
    "parent_tag_name_encoder = load('parent_tag_name_encoder.joblib') \n",
    "random_forest_model = load('rf_ml_model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractPubDateFromHTML():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.columns_to_consider = ['tag_name', 'parent_tag_name', 'ancestors_count', 'children_count',\n",
    "                                    'tag_depth','tag_position_among_siblings', 'text_length','clean_text_length',\n",
    "                                    'total_classes', 'total_numbericals', 'total_numerical_groups', 'text']\n",
    "        self.is_date_tag_names = ['b', 'p', 'div', 'a', 'date', 'time', 'span', 'strong', 'tr', 'td',\n",
    "                                  'em', 'chron', 'h6', 'small', 'ul', 'li']\n",
    "        self.is_date_tag_parent_names = ['p', 'div', 'date', 'span', 'header', 'body', 'strong', 'a', 'table', 'tr',\n",
    "                                    'td', 'article', 'time', 'em', 'small', 'ul', 'figcaption', 'li']\n",
    "        self.min_text_length = 8\n",
    "        self.max_text_length = 140\n",
    "        self.threshold = 0.31\n",
    "              \n",
    "    def encode_ground_truth(self, x):\n",
    "        \n",
    "        \"\"\"return 1 if input is True else 0\"\"\"\n",
    "        return 1 if x else 0\n",
    "\n",
    "    def decode_ground_truth(self, x):\n",
    "        \"\"\"return True if input is 1 else False\"\"\"\n",
    "        return True if x else False\n",
    "    \n",
    "    def preprocess_and_cleaning(self):\n",
    "        self.df = self.df[self.df['tag_name'].isin(self.is_date_tag_names)]\n",
    "        self.df = self.df[self.df['parent_tag_name'].isin(self.is_date_tag_parent_names)]\n",
    "        self.df = self.df[~self.df.text.isna()]\n",
    "        self.df = self.df[((self.df['text_length'] >= self.min_text_length) &\n",
    "                           (self.df['text_length'] <= self.max_text_length))]\n",
    "        self.df = self.df[self.df['total_numerical_groups'] > 0]\n",
    "        self.df = self.df[self.columns_to_consider]\n",
    "        \n",
    "        self.df = self.df.reset_index(drop=False)\n",
    "        html_text_df = self.df[['text']]\n",
    "        self.df = self.df.drop(['text', 'index'], axis=1)\n",
    "        \n",
    "        test_tag_name_encoded = tag_name_encoder.transform(self.df['tag_name'])\n",
    "        test_parent_tag_name_encoded = parent_tag_name_encoder.transform(self.df['parent_tag_name'])\n",
    "        \n",
    "        self.df = self.df.drop(['tag_name', 'parent_tag_name'], axis=1)\n",
    "        featurised_data = np.hstack([test_tag_name_encoded, test_parent_tag_name_encoded, self.df.values])\n",
    "\n",
    "        return featurised_data, html_text_df\n",
    "    \n",
    "    def fetch_published_date(self):\n",
    "        featurised_data, html_text_df = self.preprocess_and_cleaning()\n",
    "        \n",
    "        html_text_df['is_date_present_proba'] = [i[1] for i in random_forest_model.predict_proba(featurised_data)]\n",
    "        html_text_df['is_date_present'] = html_text_df['is_date_present_proba'].apply(lambda x: True if x>=self.threshold else False)\n",
    "        html_text_df = html_text_df.sort_values(by=['is_date_present_proba'], ascending=False)\n",
    "        return html_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractPublishedDate():\n",
    "    \n",
    "    def __init__(self, url, df):\n",
    "        self.ml_model = ExtractPubDateFromHTML(df)\n",
    "    \n",
    "    def extract_published_date(self):\n",
    "        return self.ml_model.fetch_published_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/\n"
     ]
    }
   ],
   "source": [
    "url = \"\"\"https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/\"\"\"\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24 Nov 2020'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_encoder = HtmlEncoder(url)\n",
    "html_encoder.transform()\n",
    "pub_date_extractor = ExtractPublishedDate(url, html_encoder.get_html_df())\n",
    "tmp = pub_date_extractor.extract_published_date()\n",
    "tmp.iloc[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_date_present_proba</th>\n",
       "      <th>is_date_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24 Nov 2020</td>\n",
       "      <td>0.758755</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rules in Veto v2 are now written in plain Go b...</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>These are backed by two small deployments whic...</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rohan Verma\\n(Software Engineer)24 Nov 2020Hom...</td>\n",
       "      <td>0.017934</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A lesson in creating and using niche business ...</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohan Verma\\n(Software Engineer)24 Nov 2020Hom...</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>govaluate:\\n1319773 907 ns/op\\ngo-plugins:\\n27...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_date_present_proba  \\\n",
       "3                                        24 Nov 2020               0.758755   \n",
       "5  Rules in Veto v2 are now written in plain Go b...               0.028571   \n",
       "6  These are backed by two small deployments whic...               0.028571   \n",
       "1  Rohan Verma\\n(Software Engineer)24 Nov 2020Hom...               0.017934   \n",
       "0  A lesson in creating and using niche business ...               0.010791   \n",
       "2  Rohan Verma\\n(Software Engineer)24 Nov 2020Hom...               0.008147   \n",
       "4  govaluate:\\n1319773 907 ns/op\\ngo-plugins:\\n27...               0.000000   \n",
       "\n",
       "   is_date_present  \n",
       "3             True  \n",
       "5            False  \n",
       "6            False  \n",
       "1            False  \n",
       "0            False  \n",
       "2            False  \n",
       "4            False  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['is_date_present'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions\n",
    "1. use NER\n",
    "2. backend rendering tools like puppeteer, selenium\n",
    "3. Use more training data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
